{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0855d0",
   "metadata": {},
   "source": [
    "# Timescale Vector Store (PostgreSQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d1c538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:14.461233Z",
     "start_time": "2023-06-08T13:06:14.451565Z"
    }
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# Uncomment to see debug logs\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.indices.vector_store import VectorStoreIndex\n",
    "from llama_index.vector_stores import TimescaleVectorStore\n",
    "import textwrap\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26c71b6d",
   "metadata": {},
   "source": [
    "### Setup OpenAI\n",
    "The first step is to configure the openai key. It will be used to created embeddings for the documents loaded into the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b86621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:16.584215Z",
     "start_time": "2023-06-08T13:06:16.576508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get openAI api key by reading local .env file\n",
    "# The .env file should contain a line starting with `OPENAI_API_KEY=sk-`\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# OR set it explicitly \n",
    "#import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<your key>\"\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "### Loading documents\n",
    "Load the documents stored in the `paul_graham_essay` using the SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c154dd4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:19.009847Z",
     "start_time": "2023-06-08T13:06:19.001593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: ecd1868c-7484-4aab-b7ba-6c70e0ae27df\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bd24f0a",
   "metadata": {},
   "source": [
    "### Get a Timescale service URL\n",
    "You need a service url to connect to the Timescale instance.\n",
    "\n",
    "To connect to your PostgreSQL database, you'll need your service URI, which can be found in the cheatsheet file you downloaded after creating a new database. The URI will look something like this: `postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d61e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the service url by reading local .env file\n",
    "# The .env file should contain a line starting with `TIMESCALE_SERVICE_URL=postgresql://`\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "TIMESCALE_SERVICE_URL = os.environ[\"TIMESCALE_SERVICE_URL\"]\n",
    "\n",
    "# OR set it explicitly\n",
    "# TIMESCALE_SERVICE_URL = \"postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0232fd1",
   "metadata": {},
   "source": [
    "### Create the index\n",
    "Here we create an index backed by Timescale using the documents loaded previously. TimescaleVectorStore takes a few arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731da62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:23.856002Z",
     "start_time": "2023-06-08T13:06:20.486349Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_store = TimescaleVectorStore.from_params(\n",
    "    service_url=TIMESCALE_SERVICE_URL,\n",
    "    table_name=\"paul_graham_essay\",\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "### Query the index\n",
    "We can now ask questions using our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a2bcc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:29.486725Z",
     "start_time": "2023-06-08T13:06:27.565039Z"
    }
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Did the author work at YC?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf55bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:32.686121Z",
     "start_time": "2023-06-08T13:06:32.680098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the author did work at YC.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:41.307336Z",
     "start_time": "2023-06-08T13:06:34.185641Z"
    }
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdf5287f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:06:44.174719Z",
     "start_time": "2023-06-08T13:06:44.163087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author worked on writing and programming growing up. They wrote short stories and tried writing\n",
      "programs on an IBM 1401 computer. They also built a microcomputer and started programming on it,\n",
      "writing simple games and a word processor.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Querying existing index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:07:11.849139Z",
     "start_time": "2023-06-08T13:07:09.040607Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "\n",
    "vector_store = TimescaleVectorStore.from_params(\n",
    "    service_url=TIMESCALE_SERVICE_URL,\n",
    "    table_name=\"paul_graham_essay\",\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T13:07:19.217191Z",
     "start_time": "2023-06-08T13:07:19.204408Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author worked on writing and programming outside of school. They wrote short stories and tried\n",
      "writing programs on an IBM 1401 computer. They also built a microcomputer and started programming on\n",
      "it, writing simple games and a word processor.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fcc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
